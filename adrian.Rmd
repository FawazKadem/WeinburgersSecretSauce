---
title: "Adrian"
output: html_notebook
---

%% BASE DATA WRANGLING

Load libraries
```{r}
library(tidyverse)
library(jsonlite)
```

Import JSON data to a datatable
```{r}
data <- fromJSON("train.json")
head(data)
```

Create LONG version of the data (split ingredients column into seperate rows with duplicated id and cuisine values)
```{r}
#using the unnest function from tidyr does this very well
dataLong <- unnest(data, ingredients)
head(dataLong)
```

Create WIDE version of data (spread ingredients across columns to make dummy variables)
```{r}
dataTidy <- dataLong %>%
  mutate(yesno = 1) %>%
  distinct %>%
  spread(ingredients, yesno, fill = 0)

head(dataTidy)
```

%% EXPLORING VARIABLES

Explore instances of each cuisine type
```{r}
cuisineCounts <- dataTidy %>%
  group_by(cuisine) %>%
  tally
```

Remove ingredients with less than X occurances
```{r}
ingredientCounts <- dataLong %>% 
  group_by(ingredients) %>%
  tally

#get ingredients > 10 frequency
frequent_ing <- ingredientCounts %>% 
  filter(n >= 2) %>%
  select(ingredients)

#filter out
dataLongFiltered <- dataLong %>% 
  filter(ingredients %in% frequent_ing$ingredients)
```

RE-Spread ingredients across columns to make dummy variables (make data wide)
```{r}
dataTidyFiltered <- dataLongFiltered %>%
  mutate(yesno = 1) %>%
  distinct %>%
  spread(ingredients, yesno, fill = 0)

head(dataTidyFiltered)
```

% PREPARE DATA FOR MODELING

Create dataset for decision tree
```{r}
#copy dataset
dataTree <- dataTidyFiltered
#remove useless ID column
dataTree$id <- NULL
#take a smaller sample of observations - 20%
dataTree <- dataTree %>% sample_frac(0.1)
#preview the data
head(dataTree)
```

Create testing and training sets from data
```{r}
num_samples = dim(dataTree)[1]
sampling.rate = 0.8
training <- sample(1:num_samples, sampling.rate * num_samples, replace=FALSE) 
trainingSet <- subset(dataTree[training, ])
testing <- setdiff(1:num_samples,training)
testingSet <- subset(dataTree[testing, ])
```


%% KNN MODEL

Strip labels from the data
```{r}
# Get the features of the training set
trainingfeatures <- subset(trainingSet, select=c(-cuisine))
# Get the labels of the training set
traininglabels <- trainingSet$cuisine
# Get the features of the testing set
testingfeatures <- subset(testingSet, select=c(-cuisine))
```

Create model and predict
```{r}
# Load the classification library
library(class)
# call KNN with k=3
predictedLabels = knn(trainingfeatures,testingfeatures,traininglabels,k=3)

# Get the number of data points in the test set
sizeTestSet = dim(testingSet)[1]
# Get the number of data points that are misclassified
error = sum(predictedLabels != testingSet$cuisine)
# Calculate the misclassification rate
misclassification_rate = error/sizeTestSet
# Display the misclassification rate
print(misclassification_rate)
```


%% DECISION TREE MODEL


Load library
```{r}
library(rpart)
```

Create decision tree model and preview
```{r}
decTreeModel <- rpart(cuisine ~ .,data=trainingSet, method = "class")

#Display the tree
plot(decTreeModel, margin=0.1)
text(decTreeModel)
```

Prune tree
```{r}
plotcp(decTreeModel)
```


```{r}
pruned_decTreeModel = prune(decTreeModel, cp=0.013)
# Display pruned tree
plot(pruned_decTreeModel, margin=0.1)
text(pruned_decTreeModel)
```


# Perform prdictions for the testing set
```{r}
predictedLabels<-predict(pruned_decTreeModel, testingSet, type = "class")
# Get the number of data points in the test set
sizeTestSet = dim(testingSet)[1]
# Get the number of data points that are misclassified
error = sum(predictedLabels != testingSet$cuisine)
# Calculate the misclassification rate
misclassification_rate = error/sizeTestSet
# Display the misclassification rate
print(error)
print(misclassification_rate)
```


%% EXPLORATORY TEXT CLUSTERING

Install packages
```{r}
library(stringdist)
library(RCurl)
```

```{r}
foodSmall <- dataLong[1:50,3]
head(foodSmall)
length(unique(foodSmall))
```

```{r}
uniqueSurg <- unique(as.character(foodSmall))
distanceSurg <- stringdistmatrix(uniqueSurg,uniqueSurg,method = "jw")
rownames(distanceSurg) <- uniqueSurg
hc <- hclust(as.dist(distanceSurg))
plot(hc)
rect.hclust(hc,k=20)

#dfClust <- data.frame(uniqueSurg, cutree(hc, k=400))
#names(dfClust) <- c('Surgery Name','cluster')
#plot(table(dfClust$cluster))
```

